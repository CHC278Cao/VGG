{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class Vgg19(object):\n",
    "    def __init__(self, x, num_classes, keep_pro, weights_path = None, skip)\n",
    "    self.x = x\n",
    "    self.num_classes = num_classes\n",
    "    self.keep_pro = keep_pro\n",
    "    \n",
    "    if weights_path is not None:\n",
    "        self.weights_path = weights_path\n",
    "        self.weights_dict = np.load(self.weights_path, encoding = \"latin1\").item()\n",
    "    else:\n",
    "        self.weights_path = None\n",
    "    # skip layers which will load pretrianed weights\n",
    "    # leave some layer which is not trainable\n",
    "    self.skip = skip\n",
    "    self.buildVgg()\n",
    "    \n",
    "    # train_mode \n",
    "    def buildVgg(self, train_mode = True):\n",
    "        conv1_1 = self.conv2d(\"conv1_1\", self.x, kernel = 3, stride = 1, out_dimension = 64)\n",
    "        conv1_2 = self.conv2d(\"conv1_2\", conv1_1, kernel = 3, stride = 1, out_dimension = 64)\n",
    "        pool1 = self.pool2d(\"pool1\", conv1_2, ksize = 2, stride = 2)\n",
    "        \n",
    "        conv2_1 = self.conv2d(\"conv2_1\", pool1, kernel = 3, stride = 1, out_dimension = 128)\n",
    "        conv2_2 = self.conv2d(\"conv2_2\", conv2_1, kernel = 3, stride = 1, out_dimension = 128)\n",
    "        pool2 = self.pool2d(\"pool2\", conv2_2, ksize = 2, stride = 2)\n",
    "        \n",
    "        conv3_1 = self.conv2d(\"conv3_1\", pool2, kernel = 3, stride = 1, out_dimension = 256)\n",
    "        conv3_2 = self.conv2d(\"conv3_2\", conv3_1, kernel = 3, stride = 1, out_dimension = 256)\n",
    "        conv3_3 = self.conv2d(\"conv3_3\", conv3_2, kernel = 3, stride = 1, out_dimension = 256)\n",
    "        conv3_4 = self.conv2d(\"conv3_4\", conv3_3, kernel = 3, stride = 1, out_dimension = 256)\n",
    "        pool3 = self.pool2d(\"pool3\", conv3_4, ksize = 2, stride = 2)\n",
    "        \n",
    "        conv4_1 = self.conv2d(\"conv4_1\", pool3, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        conv4_2 = self.conv2d(\"conv4_2\", conv4_1, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        conv4_3 = self.conv2d(\"conv4_3\", conv4_2, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        conv4_3 = self.conv2d(\"conv4_4\", conv4_3, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        pool4 = self.pool2d(\"pool4\", conv4_4, ksize = 2, stride = 2)\n",
    "        \n",
    "        conv5_1 = self.conv2d(\"conv5_1\", pool4, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        conv5_2 = self.conv2d(\"conv5_2\", conv5_1, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        conv5_3 = self.conv2d(\"conv5_3\", conv5_2, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        conv5_4 = self.conv2d(\"conv5_4\", conv5_3, kernel = 3, stride = 1, out_dimension = 512)\n",
    "        pool5 = self.pool2d(\"pool5\", conv5_4, ksize = 2, stride = 2)\n",
    "        \n",
    "        fc_in = tf.reshape(pool5, shape = [-1, 7*7*512])\n",
    "        fc6 = self.fcLayer(\"fc6\", fc_in, 7*7*512, 4096, reluFlag = True)\n",
    "        # if train_mode is True, then the model will apply dropout,\n",
    "        # for test, the dropout = 1.0, which means no dropout\n",
    "        dropout6 = tf.cond(train_mode, lambda: tf.nn.dropout(fc6, self.keep_pro), lambda: fc6)\n",
    "        \n",
    "        fc7 = self.fcLayer(\"fc7\", dropout6, 4096, 4096, reluFlag = True)\n",
    "        # same as fc6\n",
    "        dropout7 = tf.cond(train_mode, lambda: tf.nn.dropout(fc7, self.keep_pro), lambda: fc7)\n",
    "        # out_size = num_classes\n",
    "        fc8 = self.fcLayer(\"fc8\", dropout7, 4096, self.num_classes, reluFlag = True)\n",
    "        \n",
    "        self.out = tf.nn.softmax(fc8, name = \"out\")\n",
    "        \n",
    "        \n",
    "    def _get_var(self, name, idx, var_name, shape, initializer):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            name: scope name\n",
    "            idx: one scope include \"weights\" and \"biases\", idx is index of variables\n",
    "            var_name: \"weights\" and \"biases\"\n",
    "            initial_value: to initialize the variables\n",
    "        \"\"\"\n",
    "        if self.weights_path is not None and name in self.weights_dict:\n",
    "            if name not in self.skip:\n",
    "                with tf.variable_scope(name, reuse = True):\n",
    "                    value = sess.run(tf.get_variable(var_name, trainable = False).assign(self.weights_dict[name][idx]))\n",
    "            value = sess.run(tf.get_variable(var_name, trainable = True).assign(self.weights_dict[name][idx]))\n",
    "        else:\n",
    "            value = tf.get_variable(name = var_name, shape = shape, initializer = initializer, dtype = tf.float32)\n",
    "               \n",
    "        return value\n",
    "    \n",
    "    def conv2d(self, name, input_x, kernel, stride, out_dimension, padding = \"SAME\"):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            name: scope_name, to check if the scope_name is in weights_dict, then get pretrainer weights\n",
    "            input_x: input for convolutional layer, shape = [batch_size, height, width, dimension]\n",
    "            kernel: kernel size\n",
    "            stride: stride for convolution caculation\n",
    "            out_dimension: the dimension for output\n",
    "        \"\"\"\n",
    "        witf tf.scope_name(name) as scope:\n",
    "            in_dimension = int(input_x.get_size().as_list()[-1])\n",
    "            w = self._get_var(name, 0, \"weights\", shape = [kernel, kernel, in_dimension, out_dimension],\n",
    "                             initializer = tf.truncated_normal(stddev = 0.01))\n",
    "            b = self._get_var(name, 1, \"biases\", shape = [out_dimension],\n",
    "                             initializer = tf.constant_initializer(0.0))\n",
    "            out = tf.nn.conv2d(input_x, w, stride = [1, stride, stride, 1], padding = padding)\n",
    "            out = tf.bias_add(out, b)\n",
    "            conv = tf.relu(out)\n",
    "        return conv\n",
    "    \n",
    "    def pool2d(self, name, input_x, ksize, stride, padding = \"SAME\"):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            name: name for operation\n",
    "            input_x: input for pooling layer\n",
    "            ksize: the size of window, shape = [1, height, width, 1]\n",
    "            stride: the stride step shape = [1, height, width, 1]\n",
    "        \"\"\"\n",
    "        return tf.nn.max_pool(input_x, ksize = [1, ksize, ksize, 1], stride = [1, stride, stride, 1]\n",
    "                                 padding = padding, name = name)\n",
    "    \n",
    "    def fcLayer(self, name, input_x, in_size, out_size, reluFlag):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            name: the name for scope\n",
    "            input_x: input for fully connected layer\n",
    "            in_size, out_size: size to determine the kernel in fc layer\n",
    "            reluFlag: flag determines if the out will use relu\n",
    "        \"\"\"\n",
    "        with tf.scope_name(name) as scope:\n",
    "            w = self._get_var(name, 0, \"weights\", shape = [in_size, out_size],\n",
    "                              initializer = tf.truncated_normal(stddev = 0.01))\n",
    "            b = self._get_var(name, 1, \"biases\", shape = [out_size],\n",
    "                             initializer = tf.constant_initializer(0.0))\n",
    "            out = tf.nn.bias_add(tf.matmul(input_x, w), b)\n",
    "            if reluFlag:\n",
    "                fc = tf.nn.relu(out)\n",
    "            else:\n",
    "                fc = out\n",
    "        return fc\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
